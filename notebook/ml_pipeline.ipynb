{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f228664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paths\n",
    "train_dir = \"../data/train\"\n",
    "test_dir = \"../data/test\"\n",
    "classes = ['fall_armyworm', 'grasshopper', 'healthy', 'leaf_beetle', 'leaf_blight', 'leaf_spot', 'streak_virus']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fe5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation & Generators\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568af4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Setup\n",
    "base_model = MobileNetV2(include_top=False, input_shape=(img_size, img_size, 3), weights='imagenet')\n",
    "base_model.trainable = False  # Freeze base\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(classes), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d6c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save(\"../models/maize_disease_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy & Loss\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3632268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with Confusion Matrix & Classification Report\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "print(classification_report(true_classes, y_pred, target_names=class_labels))\n",
    "\n",
    "cm = confusion_matrix(true_classes, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca3de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a Single Image (Optional Cell)\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img_path = \"../data/test/leaf_spot/sample.jpg\"  # Replace with your own test image\n",
    "img = image.load_img(img_path, target_size=(img_size, img_size))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = preprocess_input(img_array)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "pred = model.predict(img_array)\n",
    "predicted_class = class_labels[np.argmax(pred)]\n",
    "confidence = np.max(pred)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Prediction: {predicted_class} ({confidence:.2f})\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
